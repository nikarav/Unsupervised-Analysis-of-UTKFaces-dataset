{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "071c2a72-75d3-4fe5-92cf-b5d026504b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io, img_as_ubyte\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.preprocessing as preproc\n",
    "import py_pcha\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import random\n",
    "import copy\n",
    "import random\n",
    "\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "991a6259-b5c0-4cd0-86b3-a4b322df85f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "_SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7737e667-cbaf-4f26-acf9-545466ffde30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths for image files, labels etc\n",
    "faces_path = \"../data/Faces/\"\n",
    "labels_path = \"../data/labels.csv\"\n",
    "names_path = \"../data/filenames.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ca3fd89-1cd1-4c0f-9b70-eccf3812aa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read labels as pandas object from labels.csv\n",
    "labels_columns = ['age', 'gender', 'race']\n",
    "labels = pd.read_csv(labels_path)\n",
    "labels = pd.DataFrame(data=labels.values, columns=labels_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c8d5344-18eb-4bb2-b059-f73b51163f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a random image to get dimensions\n",
    "test_img_name = 0\n",
    "test_img = io.imread(faces_path+f\"{test_img_name}.jpg\", as_gray=True)\n",
    "h, w = test_img.shape\n",
    "del test_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4f142ff-9334-470f-8b0a-0547ff6ff884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # filter labels\n",
    "# def filter_by_age(df, fromAge, toAge):\n",
    "#     return df[(df.age >= fromAge) & (df.age <=toAge)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e3f8fe4-93a6-4c28-889e-b295fe48497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_labels = filter_by_age(labels, 10, 30 )\n",
    "# filtered_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de661afd-fb2c-40ae-a63c-a4269f8b034e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Select images from dataset using filtered_labels\n",
    "# X = np.empty((len(filtered_labels), h*w))\n",
    "\n",
    "# for i, index in enumerate(filtered_labels.index):\n",
    "#     #print(i,index)\n",
    "#     a = io.imread(faces_path+f\"{index}.jpg\", as_gray=True)\n",
    "#     a = img_as_ubyte(a)\n",
    "#     X[i, :] = a.reshape(1, -1)\n",
    "    \n",
    "# del a\n",
    "# print('Done loading images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c5a7368-1ff9-477b-9eed-8bb8dbd09cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate random indexes for sampling\n",
    "total_n_faces = 23704\n",
    "subset_length = 5000\n",
    "random_indexes = []\n",
    "for i in range(0, subset_length):\n",
    "    n = random.randint(0,total_n_faces)\n",
    "    random_indexes.append(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f698811-665f-466b-a5ec-15e12f05b134",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading images\n"
     ]
    }
   ],
   "source": [
    "#Select images from dataset using random indexes\n",
    "X = np.empty(shape = (subset_length, h*w))\n",
    "\n",
    "for i, index in enumerate(random_indexes):\n",
    "    #print(i,index)\n",
    "    a = io.imread(faces_path+f\"{index}.jpg\", as_gray=True)\n",
    "    a = img_as_ubyte(a)\n",
    "    X[i, :] = a.reshape(1, -1)\n",
    "    \n",
    "del a\n",
    "print('Done loading images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98454263-24d6-487d-a750-c33c4b08fb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_labels = labels.iloc[random_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60c88216-b003-4824-ae72-d1112a69f807",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 7 # num components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb5c09e4-a670-4425-8835-d0b7e8094690",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'AA'\n",
    "\n",
    "#Archetypal analysis (KNN commented out)\n",
    "if method == 'AA':\n",
    "    #Reference to book notation\n",
    "    '''\n",
    "    B = C.T\n",
    "    W = S.T\n",
    "    H = XC.T\n",
    "    SSE = Sum of Squared Errors\n",
    "    '''\n",
    "    \n",
    "    for n_comp in [2, 3, 4, 5, 7, 10, 15, 20, 25, 35, 50]:\n",
    "        # Does not require that you center data\n",
    "        XC, S, C, SSE, varexpl = py_pcha.PCHA(X.T, noc=n_components, delta=0.1)\n",
    "        X_hat = X.T @ C @ S\n",
    "        L = 0.5*np.linalg.norm(X.T-X_hat)**2\n",
    "        components = XC.T\n",
    "        SST = np.sum(np.sum(X**2))\n",
    "        \n",
    "        outfile = str(n_comp) + \"_comp_XC\"\n",
    "        np.save(outfile, XC)\n",
    "        outfile = str(n_comp) + \"_comp_S\"\n",
    "        np.save(outfile, S)\n",
    "        outfile = str(n_comp) + \"_comp_C\"\n",
    "        np.save(outfile, C)\n",
    "        outfile = str(n_comp) + \"_comp_SSE\"\n",
    "        np.save(outfile, SSE)\n",
    "        outfile = str(n_comp) + \"_comp_varexpl\"\n",
    "        np.save(outfile, varexpl)\n",
    "        outfile = str(n_comp) + \"_comp_X_hat\"\n",
    "        np.save(outfile, X_hat)\n",
    "        outfile = str(n_comp) + \"_comp_L\"\n",
    "        np.save(outfile, L)\n",
    "        outfile = str(n_comp) + \"_comp_SST\"\n",
    "        np.save(outfile, SST)\n",
    "\n",
    "\n",
    "    #knn.fit(S.T,ytrain)\n",
    "    # Xtest_transform = np.linalg.lstsq(XC, Xtest.T)[0] #solve Xtest = XC @ S for S\n",
    "    #acc = knn.score(Xtest_transform.T,ytest)\n",
    "    # X_test_hat = (XC @ Xtest_transform).T\n",
    "\n",
    "\n",
    "\n",
    "#NMF\n",
    "elif method == 'NMF':\n",
    "    # Create model init method is set to random\n",
    "    model = decomposition.NMF(n_components=n_components, init='random', random_state=0)\n",
    "    X_transformed = model.fit_transform(X)\n",
    "    L = 0.5*model.reconstruction_err_**2\n",
    "    components = model.components_ # H\n",
    "    \n",
    "    # knn.fit(X_train_transformed,ytrain)\n",
    "    # acc = knn.score(model.transform(Xtest),ytest)\n",
    "    # X_test_hat = model.transform(Xtest).dot(model.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09a47c67-3459-4845-83c8-01fafb08e5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "XC = np.load(\"2_comp_varexpl.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e727d2e0-9de2-4a31-bc8d-10af73efaf65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.92708724)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5368e0c-c81a-45a9-90f1-fb8b185491b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get indexes of the samples more significant for the archetypes\n",
    "Xmain = np.zeros((n_components,3))\n",
    "\n",
    "for i in range(len(C.T)):\n",
    "    Xmain[i,:] = np.flip(np.argsort(C.T[i]))[0,:3]\n",
    "Xmain = Xmain.astype(int) #Main samples indexes for each component\n",
    "    \n",
    "arch_len = np.array(range(len(Xmain))).reshape(-1,1)\n",
    "arch_main = np.append(arch_len, Xmain, axis = 1) #Archetype indexes and main samples indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2aa673e-5695-4238-8f7e-cb37aac48eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting functions\n",
    "n_rows = 7 #for plotting\n",
    "n_cols = 7 #for plotting\n",
    "\n",
    "left = 0.0\n",
    "right = 0.0\n",
    "bottom = 0.99\n",
    "top = 0.83\n",
    "wspace = 0.0\n",
    "hspace = 0.0\n",
    "image_shape = (h, w)\n",
    "# Function for plotting images\n",
    "def plot_components(title, components):\n",
    "    plt.figure(figsize=(2. * n_cols, 2.26 * n_rows))\n",
    "    plt.suptitle(title, size=24)\n",
    "    # For each of the first 6 observations plot\n",
    "    #start_index = random.randint(0, n)\n",
    "    for i, comp in enumerate(components):\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "        # normalize colormap\n",
    "        vmax = max(comp.max(), -comp.min())\n",
    "        plt.imshow(comp.reshape(image_shape), cmap=plt.cm.gray,\n",
    "                   interpolation='nearest',\n",
    "                   vmin=-vmax, vmax=vmax)\n",
    "        # Remove ticks from plot\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "\n",
    "    plt.subplots_adjust(left, right, bottom, top, wspace, hspace)\n",
    "    \n",
    "def plot_recons(X, title, Nplot=100):\n",
    "    plt.figure(figsize=(2. * 10, 2.26 * 10))\n",
    "    plt.suptitle(title, size=24)\n",
    "    # For each of the first 6 observations plot\n",
    "    for i in range(100):\n",
    "        plt.subplot(10, 10, i + 1)\n",
    "        # normalize colormap\n",
    "        idx = random.randint(0, 210)\n",
    "        comp = X[idx,:]\n",
    "        vmax = max(comp.max(), -comp.min())\n",
    "        plt.imshow(comp.reshape(image_shape), cmap=plt.cm.gray,\n",
    "                   interpolation='nearest',\n",
    "                   vmin=-vmax, vmax=vmax)\n",
    "        # Remove ticks from plot\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "\n",
    "    plt.subplots_adjust(left, right, bottom, top, wspace, hspace)\n",
    "    \n",
    "def plot_arch_contributors(title, arch_main):\n",
    "    '''\n",
    "    Plot each archetype (first column) and the three most contributive samples that \n",
    "    define them\n",
    "    '''\n",
    "    #plt.figure(figsize=(image_shape[0]/100 * n_components, image_shape[1]/100 * np.shape(arch_main)[1]))\n",
    "    plt.figure(figsize= (image_shape[1]/90 * np.shape(arch_main)[0], image_shape[0]/40 * n_components))\n",
    "    plt.suptitle(title, size=24)\n",
    "    pos = 0\n",
    "    j = 0\n",
    "    while j < len(arch_main):  \n",
    "        for i, sample in enumerate(arch_main[j]):\n",
    "            pos += 1\n",
    "            if i == 0:\n",
    "                comp = XC.T[sample,:]\n",
    "            else:\n",
    "                comp = X[sample,:]\n",
    "            plt.subplot(n_components, np.shape(arch_main)[1], pos)\n",
    "            # normalize colormap\n",
    "            vmax = max(comp.max(), -comp.min())\n",
    "            plt.imshow(comp.reshape(image_shape), cmap=plt.cm.gray,\n",
    "                       interpolation='nearest',\n",
    "                       vmin=-vmax, vmax=vmax)\n",
    "            # Remove ticks from plot\n",
    "            plt.xticks(())\n",
    "            plt.yticks(())\n",
    "        j += 1\n",
    "\n",
    "    plt.subplots_adjust(left, right, bottom, top, wspace, hspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a36b100-25e2-4bb0-b7c2-17395f94859f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_components(f'AA features. Variance explained by AA {1-2*L/SST}', components)\n",
    "plot_recons(X_hat.T, f'AA reconstructed digits')\n",
    "plot_arch_contributors('Archetypes and their main contributors', arch_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bee247-636a-439c-8671-695efb3c9f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Switch lables_codes to words\n",
    "labels_words = copy.deepcopy(filtered_labels)\n",
    "\n",
    "#gender\n",
    "labels_words.loc[labels_words.gender == 0, \"gender\"] = \"0_male\"\n",
    "labels_words.loc[labels_words.gender == 1, \"gender\"] = \"1_female\"\n",
    "\n",
    "#race\n",
    "labels_words.loc[labels_words.race == 0, \"race\"] = \"0_white\"\n",
    "labels_words.loc[labels_words.race == 1, \"race\"] = \"1_black\"\n",
    "labels_words.loc[labels_words.race == 2, \"race\"] = \"2_asian\"\n",
    "labels_words.loc[labels_words.race == 3, \"race\"] = \"3_indian\"\n",
    "labels_words.loc[labels_words.race == 4, \"race\"] = \"4_others\"\n",
    "\n",
    "#age in bins\n",
    "bins = [0, 2, 4, 13, 20, 60, 200]\n",
    "lab = [\"0_infant\", \"1_toddler\", \"2_kid\", \"3_teen\", \"4_adult\", \"5_old\"]\n",
    "labels_words[\"age\"] = pd.cut(labels_words[\"age\"], bins = bins, labels = lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b94a9c-e955-4413-bd36-a9c5b6d39764",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Score matrix, used to understand which labels constitute each component\n",
    "def arch_score(B, labels):\n",
    "    '''\n",
    "    Arguments:\n",
    "    labels = pandas df. Make sure that the values are unique across the whole dataset. \n",
    "             If there is an \"A\" in the first column, it must not be there in the others\n",
    "    B = n_component * n_samples (C.T). Every row describes the coefficient for each sample to \n",
    "        build the corresponding archetype\n",
    "    _____________________________________________________________________________________\n",
    "    Output:\n",
    "    score_matrix = n_component * possible labels values. Every case describes how much the \n",
    "                    corresponding label is present in the component\n",
    "    '''\n",
    "    #Get all the unique values of the various labels, sorted   \n",
    "    cols = []\n",
    "    for i in range(labels.shape[1]):\n",
    "        cols += sorted(list(labels.iloc[:,i].unique()))\n",
    "    labels_values = np.array(cols) #List of the possible values of the labels, ordered \"inside\" each column\n",
    "    #print(\"Labels:\",labels_values)\n",
    "    score_matrix = np.zeros(shape=(np.shape(B)[0], len(labels_values)))\n",
    "    \n",
    "    for component_i in range(np.shape(score_matrix)[0]):\n",
    "        for label_i in range(len(list(labels_values))):\n",
    "            for sample_i in range(np.shape(B)[1]):\n",
    "                if labels_values[label_i] in list(labels.iloc[sample_i,:]):\n",
    "                    score_matrix[component_i, label_i] += B[component_i,sample_i]\n",
    "    \n",
    "    return score_matrix, labels_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80bad27-5ce0-4729-b600-28da77272c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gender-switch functions\n",
    "def gender_switch_component_index(wj, labels, scores):\n",
    "    '''\n",
    "    Input:\n",
    "    wj = row in matrix W corresponding to the image to switch gender of\n",
    "    labels = list of the possible labels in the components scores matrix\n",
    "             (output of the function arch_score)\n",
    "    scores = n_components * n_labels . Components scores matrix (output of the function arch_score)\n",
    "    ___________________________________________________________________________________\n",
    "    \n",
    "    Output:\n",
    "    winner_index = index of the selected component. Increase this component\n",
    "                    to switch gender\n",
    "    '''\n",
    "    #Find the weighted average of the components scores of the input \n",
    "    mean_component_score = wj @ scores\n",
    "    \n",
    "    #Get the indexes of the genders\n",
    "    f_i = list(np.where(labels == '1_female'))\n",
    "    m_i = list(np.where(labels == '0_male'))\n",
    "    gender_i = f_i + m_i\n",
    "    distances = np.zeros(np.shape(scores)[0])\n",
    "\n",
    "    for r in range(np.shape(scores)[0]):\n",
    "        distance = np.linalg.norm(scores[r,:] - mean_component_score)\n",
    "        mf = np.linalg.norm(scores[r,gender_i] - mean_component_score[0,gender_i])\n",
    "\n",
    "        distances[r] = distance - 2 * mf\n",
    "\n",
    "    winner_index = np.argmin(distances)\n",
    "    \n",
    "    return winner_index\n",
    "\n",
    "def add_component(wj, comp_i, coefficient=0.3):\n",
    "    '''\n",
    "    Input\n",
    "    wj = row in matrix W corresponding to the image to switch gender of\n",
    "    comp_i = index of the component to add\n",
    "    coefficient = [0-1] How much to increase the new component\n",
    "    ____________________________________________________________________\n",
    "    Output\n",
    "    new = coefficients of the components to reconstruct the new image\n",
    "    '''\n",
    "    new = copy.deepcopy(wj) #Deepcopy to not mess with original matrix\n",
    "    \n",
    "    #Proportionally decrease old components \n",
    "    for component in range(len(new)):\n",
    "        new[component] = new[component] * (1 - coefficient)\n",
    "    \n",
    "    #Add new component\n",
    "    new[0, comp_i] += coefficient\n",
    "    \n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a6e44f-83a4-4798-973e-355c7f3b790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "archetype_scores, score_labels = arch_score(B = C.T, labels = labels_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21c452a-776a-410b-9e54-73c1d261d844",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Switch gender of the first image\n",
    "ind = 13\n",
    "win = gender_switch_component_index(wj=S.T[ind], labels=score_labels, scores=archetype_scores)\n",
    "new_gender_w = add_component(wj=S.T[ind], comp_i=win, coefficient=0.34)\n",
    "new_fem = new_gender_w @ XC.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596c1fe0-c641-4587-9662-2d466c2f560b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image (ind)\n",
    "plt.imshow((X_hat.T[ind,:]).reshape(h,w), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc0e6ff-3c09-456e-baa1-31a484228390",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image (ind) (gender switched)\n",
    "plt.imshow((new_fem[0,:]).reshape(h,w), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9523b42c-f59f-419e-ad83-5f024553a5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4dfe0d-1797-45d1-916f-2b04c6bb959a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
