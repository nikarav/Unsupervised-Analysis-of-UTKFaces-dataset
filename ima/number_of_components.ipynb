{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1840eeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ima_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA, FastICA, NMF, DictionaryLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e24a30f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "\n",
    "_SHUFFLE = True\n",
    "_SEED = 0\n",
    "_LIMITS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc82b051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths to labels, faces, etc.\n",
    "\n",
    "faces_path = \"../data/Faces/\"\n",
    "labels_path = \"../data/labels.csv\"\n",
    "names_path = \"../data/filenames.txt\"\n",
    "\n",
    "data_set_gray_npy = \"data_gray.npy\" # All of the observed data saved in anpy file. See from_face_images_to_npy.py\n",
    "data_set_rgb_npy = \"data_rgb.npy\" # Unused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12b8f037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels as pandas object from labels.csv file.\n",
    "labels = ima_utils.get_labels_df(labels_path=labels_path, names_path=names_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a706cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I limit the age. For legal reasons, not so that I have fewer data and to avoid the babies.\n",
    "\n",
    "if _LIMITS:\n",
    "    age_min = 18\n",
    "    age_max = 80\n",
    "    labels = labels.loc[(labels.age >= age_min) & (labels.age <= age_max)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3443f505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put age in bins\n",
    "\n",
    "age_bin_width_years = 25\n",
    "ages = labels.age.values//age_bin_width_years  # bin_width fully lived\n",
    "labels.drop(['age'], axis=1, inplace=True)\n",
    "labels['age_bin'] = ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd9f465b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the whole image data set to train and test sets. Only the train data set will be used.\n",
    "\n",
    "train_dataset_idx, test_dataset_idx = train_test_split(labels.index.to_list()) # The indices of the images to be split\n",
    "\n",
    "X = np.load(data_set_gray_npy) # Load my dataset (full)\n",
    "\n",
    "data_train, data_test = X[train_dataset_idx], X[test_dataset_idx]\n",
    "labels_train, labels_test = labels.loc[train_dataset_idx], labels.loc[test_dataset_idx]\n",
    "labels_train = labels_train.reset_index()\n",
    "labels_test = labels_test.reset_index()\n",
    "del X, labels  # to avoid accessing the test set and also to save ram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c076a716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a random image to get dimensions\n",
    "\n",
    "h, w = ima_utils.get_dimensions_from_an_image(faces_path, 0, as_gray=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "848aa11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select images from data_train to load\n",
    "\n",
    "n_elements_from_label = 1000\n",
    "label_to_choose_from = \"random\"\n",
    "images_to_load = ima_utils.pick_n_from_label(labels_train, n_elements_from_label, label_to_choose_from, shuffle=_SHUFFLE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49a7d9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select from the data_train set the images_to_load\n",
    "\n",
    "X = data_train[images_to_load, :]  # X is a new name for my data. The whole data, previously named X, set was deleted\n",
    "\n",
    "labels_loaded = labels_train.loc[images_to_load]\n",
    "labels_loaded = labels_loaded.reset_index()\n",
    "\n",
    "y_age = labels_loaded.age_bin.values\n",
    "y_race = labels_loaded.race.values\n",
    "y_gender = labels_loaded.gender.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84b4bb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp2/ipykernel_5348/2963510948.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mnum_comp\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mnmf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNMF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_comp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_SEED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'random'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mnew_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mima_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_decomposition_reconstruction_error_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnmf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Loss {new_loss}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1340\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1341\u001b[0m         \"\"\"\n\u001b[1;32m-> 1342\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1343\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, W, H)\u001b[0m\n\u001b[0;32m   1309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1310\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massume_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1311\u001b[1;33m             W, H, n_iter_ = non_negative_factorization(\n\u001b[0m\u001b[0;32m   1312\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m                 \u001b[0mupdate_H\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py\u001b[0m in \u001b[0;36mnon_negative_factorization\u001b[1;34m(X, W, H, n_components, init, update_H, solver, beta_loss, tol, max_iter, alpha, l1_ratio, regularization, random_state, verbose, shuffle)\u001b[0m\n\u001b[0;32m   1071\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1072\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'cd'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1073\u001b[1;33m         W, H, n_iter = _fit_coordinate_descent(X, W, H, tol, max_iter,\n\u001b[0m\u001b[0;32m   1074\u001b[0m                                                \u001b[0ml1_reg_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml1_reg_H\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1075\u001b[0m                                                \u001b[0ml2_reg_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml2_reg_H\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py\u001b[0m in \u001b[0;36m_fit_coordinate_descent\u001b[1;34m(X, W, H, tol, max_iter, l1_reg_W, l1_reg_H, l2_reg_W, l2_reg_H, update_H, verbose, shuffle, random_state)\u001b[0m\n\u001b[0;32m    519\u001b[0m         \u001b[1;31m# Update H\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mupdate_H\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             violation += _update_coordinate_descent(X.T, Ht, W, l1_reg_H,\n\u001b[0m\u001b[0;32m    522\u001b[0m                                                     l2_reg_H, shuffle, rng)\n\u001b[0;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py\u001b[0m in \u001b[0;36m_update_coordinate_descent\u001b[1;34m(X, W, Ht, l1_reg, l2_reg, shuffle, random_state)\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m     \u001b[0mHHt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m     \u001b[0mXHt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[1;31m# L2 regularization corresponds to increase of the diagonal of HHt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    150\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Find for a decomposition method, here NMF, the optimal number of components, based on relative loss\n",
    "\n",
    "max_iter = 500\n",
    "tolerance = 0.01\n",
    "\n",
    "rel_loss = 100\n",
    "loss = 1\n",
    "\n",
    "num_comp = 1\n",
    "i=1\n",
    "while rel_loss>= tolerance:\n",
    "    print(f'\\nRun {i}')\n",
    "    num_comp += 1\n",
    "    i += 1\n",
    "    nmf = NMF(n_components=num_comp, random_state=_SEED, init='random',max_iter=max_iter).fit(X)\n",
    "    new_loss = ima_utils.get_decomposition_reconstruction_error_score(nmf, X)\n",
    "    print(f\"Loss {new_loss}\")\n",
    "    rel_loss = np.abs(new_loss-loss)/loss\n",
    "    print(f\"Relative change in loss {rel_loss}\")\n",
    "    loss = new_loss\n",
    "\n",
    "print(f'NMF number of components {num_comp} wit loss: {loss}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
